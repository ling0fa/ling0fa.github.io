<!DOCTYPE html><html lang="null"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description"><title>一个简单的Python爬虫 | 王乐心的博客</title><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/4.2.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.0/grids-responsive-min.css"><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.6.3/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.0.0/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">一个简单的Python爬虫</h1><a id="logo" href="/.">王乐心的博客</a><p class="description"></p></div><div id="nav-menu"><a href="/." class="current"><i class="fa fa-home"> Start</i></a><a href="/archives/"><i class="fa fa-archive"> Archiv</i></a><a href="/about/"><i class="fa fa-user"> Über</i></a><a href="/atom.xml"><i class="fa fa-rss"> RSS</i></a></div></div><div id="layout" class="pure-g"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">一个简单的Python爬虫</h1><div class="post-meta">Apr 10, 2016<script src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js" async></script><span id="busuanzi_container_page_pv"> | <span id="busuanzi_value_page_pv"></span><span> Hits</span></span></div><div class="post-content"><p>由于我经常逛微博，看到某些博主的图片都很好看（你懂的），就想干脆下载到本地，于是萌生了搞个爬虫的想法。之前听说 Python 网络爬虫，听起来高大上，在实践了后感觉也不是什么难事，现在来看自己实现的爬虫都很简单，以后要实现更复杂的爬虫的话，看了这篇博客和代码，能让自己也能快速的捡起来，进行二次开发。</p>
<p>除了需要 Python 环境外，还需要安装 requests、BeautifulSoup4等。获取微博页面内容时使用cookie的方式，这样不需要用户名和密码就可以请求到微博。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ pip install requests BeautifulSoup4</div></pre></td></tr></table></figure></p>
<p>好了，准备工作基本OK。这个爬虫是从新浪微博上爬取某个博主的所有图片，在观察了新浪微博里图片URL的规律后，发现链接主要有3部分构成，如下。img-key 部分我估计是存取图片的唯一ID值，part2 取不同的值，会得到不同尺寸的图片，最大尺寸时，part2取值 ‘large’，有了这个规律就好办了，将页面所有图片满足3段式的链接中间那部分替换成’large’，再下载图片即可。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">http://ww2.sinaimg.cn/part2/img-key.jpg</div></pre></td></tr></table></figure>
<p>另外，由于使用的是 <em>weibo.cn</em> 域名，从浏览器里得到是一张图片和一个<strong>更多</strong>作为链接，点了链接才看得到所有图片，所以爬每个页面有个二次请求，将更多的图片下载下来。为了避免重复下载导致图片难以维护，保存图片时，将微博的发布日期和图片链接的MD5值组合成图片名称，这样下载到本地后，图片会以在微博上发布的日期排序，同时，再次运行爬虫时，将图片名称后半截的MD5值提取出来，在下载时候对比该图片的链接MD5值是否已经存在，避免重复下载。</p>
<p>下面是下载一个页面里所有图片的函数代码。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">download_one_page</span><span class="params">(soup, user_id, exists)</span>:</span></div><div class="line"><span class="string">"""</span></div><div class="line">download all pictures on the website</div><div class="line">:param soup: web page soup</div><div class="line">:param user_id: the weibo user id</div><div class="line">:param exists exists pic names</div><div class="line">:return: find weibo divs, return True, else False</div><div class="line">"""</div><div class="line"></div><div class="line"><span class="comment"># ten weibo div in every page</span></div><div class="line">divs = soup.find_all(div_filter_func)</div><div class="line"></div><div class="line"><span class="keyword">if</span> <span class="keyword">not</span> divs:</div><div class="line">    <span class="keyword">return</span> <span class="keyword">False</span></div><div class="line"></div><div class="line"><span class="keyword">for</span> div <span class="keyword">in</span> divs:</div><div class="line">    spans = div.find_all(<span class="string">'span'</span>)</div><div class="line">    wb_post_time = get_weibo_post_time(spans[<span class="number">1</span>].text)</div><div class="line"></div><div class="line">    <span class="comment"># abstract a link</span></div><div class="line">    all_img = div.find_all(<span class="string">'img'</span>)</div><div class="line">    img_link = filter(<span class="keyword">lambda</span> x: x.endswith(<span class="string">'.jpg'</span>), [all_img[<span class="number">0</span>].get(<span class="string">'src'</span>)] <span class="keyword">if</span> all_img <span class="keyword">else</span> [])</div><div class="line"></div><div class="line">    <span class="comment"># abstract more links</span></div><div class="line">    more_links = [link[<span class="string">'href'</span>] <span class="keyword">for</span> link <span class="keyword">in</span> div.find_all(<span class="string">'a'</span>) <span class="keyword">if</span> link.get(<span class="string">'href'</span>) <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>]</div><div class="line">    more_links_real = [x <span class="keyword">for</span> x <span class="keyword">in</span> more_links <span class="keyword">if</span> <span class="string">'picAll'</span> <span class="keyword">in</span> x]</div><div class="line">    <span class="keyword">if</span> more_links_real:</div><div class="line">        more_content = requests.get(more_links_real[<span class="number">0</span>], cookies = get_cookie())</div><div class="line">        more_soup = BeautifulSoup(more_content.content, <span class="string">'html.parser'</span>)</div><div class="line">        more_soup_urls = get_more_page_image_url(more_soup)</div><div class="line">        img_link = more_soup_urls <span class="keyword">if</span> more_soup_urls <span class="keyword">else</span> img_link</div><div class="line"></div><div class="line">    <span class="comment"># download</span></div><div class="line">    <span class="keyword">for</span> idx, link <span class="keyword">in</span> enumerate(img_link):</div><div class="line">        md5 = calculate_md5(link)</div><div class="line">        <span class="keyword">if</span> md5 <span class="keyword">not</span> <span class="keyword">in</span> exists:</div><div class="line">            large_link = replace_part2_in_link(link)</div><div class="line">            image_content = requests.get(large_link, cookies = get_cookie())</div><div class="line"></div><div class="line">            image_name = <span class="string">"&#123;&#125;&gt;&#123;&#125;_&#123;&#125;"</span>.format(wb_post_time, str(idx), md5)</div><div class="line">            <span class="keyword">with</span> open(<span class="string">'./downloads/&#123;&#125;/&#123;&#125;.jpg'</span>.format(user_id, image_name), <span class="string">'wb'</span>) <span class="keyword">as</span> jpg:</div><div class="line">                jpg.write(image_content.content)</div><div class="line"></div><div class="line">                exists.add(image_name)</div><div class="line">                print(<span class="string">'download'</span>, large_link, image_name, datetime.datetime.now())</div><div class="line">                time.sleep(random.random())</div><div class="line">        <span class="keyword">else</span>:</div><div class="line">            print(<span class="string">'jump over:'</span>, link)</div><div class="line"></div><div class="line">sleep = <span class="number">8</span> * random.random()</div><div class="line">print(<span class="string">'sleep'</span>, sleep, <span class="string">'seconds'</span>)</div><div class="line">time.sleep(sleep)</div><div class="line"><span class="keyword">return</span> <span class="keyword">True</span></div></pre></td></tr></table></figure>
<p>在某次打算爬取大量某个博主的图片时，出现了请求失败，查了资料发现是网站有反爬虫功能，于是使用了一些简单的策略，比如请求加上头消息：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">header = &#123;</div><div class="line">      <span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/49.0.2623.112 Safari/537.36'</span>,</div><div class="line">      <span class="string">'Accept'</span>: <span class="string">'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8'</span>,</div><div class="line">      <span class="string">'Accept-Language'</span>: <span class="string">'zh-CN,zh;q=0.8,en;q=0.6'</span></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>除此之外，对请求的cookie也在末尾添加随机数，每次用不同的cookie去请求，并且，每爬取完一个页面的内容，随机休眠0-8秒，这样做虽然抓取速度慢了点，但至少能保证每次抓取不会半途报错。</p>
<p>完整的代码示例<a href="https://github.com/hsqs/spiders/blob/master/weibo/weibo_miner.py" target="_blank" rel="external">点这里</a>。    </p>
</div><script type="text/javascript" src="/js/share.js?v=0.0.0" async></script><a data-url="http://yoursite.com/2016/04/10/a-simple-python-spider-md/" data-id="ciso5vdiu000299e11v1ipcfb" class="article-share-link">Aktie</a><div class="tags"><a href="/tags/python-spider/">python spider</a></div><div class="post-nav"><a href="/2016/04/17/add-env-var-on-OSX-md/" class="pre">在OS X上添加环境变量</a><a href="/2016/03/27/use-virtualenv-md/" class="next">在OS X上使用virtualenv</a></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank" class="search-form"><input type="text" name="q" maxlength="20" placeholder="Search"/><input type="hidden" name="sitesearch" value="http://yoursite.com"/></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> Kategorien</i></div></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> Tags</i></div><div class="tagcloud"><a href="/tags/Hexo/" style="font-size: 15px;">Hexo</a> <a href="/tags/教程/" style="font-size: 15px;">教程</a> <a href="/tags/python-spider/" style="font-size: 15px;">python spider</a> <a href="/tags/OS-X/" style="font-size: 15px;">OS X</a> <a href="/tags/环境变量/" style="font-size: 15px;">环境变量</a> <a href="/tags/OOP/" style="font-size: 15px;">OOP</a> <a href="/tags/scala/" style="font-size: 15px;">scala</a> <a href="/tags/Option/" style="font-size: 15px;">Option</a> <a href="/tags/mybatis/" style="font-size: 15px;">mybatis</a> <a href="/tags/virtualenv/" style="font-size: 15px;">virtualenv</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> Letzte</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2016/09/04/scala-option-and-others/">学习笔记：Scala的Option以及其他容器</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/07/30/Hello-Hexo/">Hello Hexo</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/07/02/program-with-OOP-md/">面向对象编程的一些体会</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/04/17/add-env-var-on-OSX-md/">在OS X上添加环境变量</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/04/10/a-simple-python-spider-md/">一个简单的Python爬虫</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/03/27/use-virtualenv-md/">在OS X上使用virtualenv</a></li><li class="post-list-item"><a class="post-list-link" href="/2015/12/27/some-usage-of-mybatis-md/">Mybatis使用经验总结</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> Blogroll</i></div><ul></ul><a href="http://www.example1.com/" title="site-name1" target="_blank">site-name1</a><ul></ul><a href="http://www.example2.com/" title="site-name2" target="_blank">site-name2</a><ul></ul><a href="http://www.example3.com/" title="site-name3" target="_blank">site-name3</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">© <a href="/." rel="nofollow">王乐心的博客.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a id="rocket" href="#top" class="show"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.pack.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="/css/jquery.fancybox.css?v=0.0.0"><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>