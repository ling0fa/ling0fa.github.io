<!DOCTYPE HTML>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Seite 2 | Ling0fa 的博客</title>
  
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  
  <meta property="og:site_name" content="Ling0fa 的博客"/>

  
    <meta property="og:image" content="undefined"/>
  

  <link href="/favicon.png" rel="icon">
  <link rel="alternate" href="/atom.xml" title="Ling0fa 的博客" type="application/atom+xml">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
  <!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->
  

</head>


<body>
  <header id="header" class="inner"><div class="alignleft">
  <h1><a href="/">Ling0fa 的博客</a></h1>
  <h2><a href="/"></a></h2>
</div>
<nav id="main-nav" class="alignright">
  <ul>
    
      <li><a href="/">Home</a></li>
    
      <li><a href="/archives">Archives</a></li>
    
  </ul>
  <div class="clearfix"></div>
</nav>
<div class="clearfix"></div>
</header>
  <div id="content" class="inner">
    <div id="main-col" class="alignleft"><div id="wrapper">
  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2016-04-10T06:01:39.000Z"><a href="/2016/04/10/a-simple-python-spider-md/">2016-04-10</a></time>
      
      
  
    <h1 class="title"><a href="/2016/04/10/a-simple-python-spider-md/">一个简单的Python爬虫</a></h1>
  

    </header>
    <div class="entry">
      
        <p>由于我经常逛微博，看到某些博主的图片都很好看，就想下载到本地保存起来，于是萌生了搞个爬虫的想法。之前听说 Python 网络爬虫比较方便，考虑如果使用爬虫框架的话还要二次学习，于是偷懒直接手工撸了起来。</p>
<p>除了需要 Python 环境外，还需要安装 requests、BeautifulSoup4等。获取微博页面内容时使用cookie的方式，这样不需要用户名和密码就可以请求到微博。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ pip install requests BeautifulSoup4</div></pre></td></tr></table></figure></p>
<p>好了，准备工作基本OK。这个爬虫是从新浪微博上爬取某个博主的所有图片，在观察了新浪微博里图片URL的规律后，发现链接主要有3部分构成，如下。img-key 部分我估计是存取图片的唯一ID值，part2 取不同的值，会得到不同尺寸的图片，最大尺寸时，part2取值 ‘large’，有了这个规律就好办了，将页面所有图片满足3段式的链接中间那部分替换成’large’，再下载图片即可。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">http://ww2.sinaimg.cn/part2/img-key.jpg</div></pre></td></tr></table></figure>
<p>另外，由于使用的是 <em>weibo.cn</em> 域名，从浏览器里得到是一张图片和一个<strong>更多</strong>作为链接，点了链接才看得到所有图片，所以爬每个页面有个二次请求，将更多的图片下载下来。为了避免重复下载导致图片难以维护，保存图片时，将微博的发布日期和图片链接的MD5值组合成图片名称，这样下载到本地后，图片会以在微博上发布的日期排序，同时，再次运行爬虫时，将图片名称后半截的MD5值提取出来，在下载时候对比该图片的链接MD5值是否已经存在，避免重复下载。</p>
<p>下面是下载一个页面里所有图片的函数代码。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">download_one_page</span><span class="params">(soup, user_id, exists)</span>:</span></div><div class="line"><span class="string">"""</span></div><div class="line">download all pictures on the website</div><div class="line">:param soup: web page soup</div><div class="line">:param user_id: the weibo user id</div><div class="line">:param exists exists pic names</div><div class="line">:return: find weibo divs, return True, else False</div><div class="line">"""</div><div class="line"></div><div class="line"><span class="comment"># ten weibo div in every page</span></div><div class="line">divs = soup.find_all(div_filter_func)</div><div class="line"></div><div class="line"><span class="keyword">if</span> <span class="keyword">not</span> divs:</div><div class="line">    <span class="keyword">return</span> <span class="keyword">False</span></div><div class="line"></div><div class="line"><span class="keyword">for</span> div <span class="keyword">in</span> divs:</div><div class="line">    spans = div.find_all(<span class="string">'span'</span>)</div><div class="line">    wb_post_time = get_weibo_post_time(spans[<span class="number">1</span>].text)</div><div class="line"></div><div class="line">    <span class="comment"># abstract a link</span></div><div class="line">    all_img = div.find_all(<span class="string">'img'</span>)</div><div class="line">    img_link = filter(<span class="keyword">lambda</span> x: x.endswith(<span class="string">'.jpg'</span>), [all_img[<span class="number">0</span>].get(<span class="string">'src'</span>)] <span class="keyword">if</span> all_img <span class="keyword">else</span> [])</div><div class="line"></div><div class="line">    <span class="comment"># abstract more links</span></div><div class="line">    more_links = [link[<span class="string">'href'</span>] <span class="keyword">for</span> link <span class="keyword">in</span> div.find_all(<span class="string">'a'</span>) <span class="keyword">if</span> link.get(<span class="string">'href'</span>) <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>]</div><div class="line">    more_links_real = [x <span class="keyword">for</span> x <span class="keyword">in</span> more_links <span class="keyword">if</span> <span class="string">'picAll'</span> <span class="keyword">in</span> x]</div><div class="line">    <span class="keyword">if</span> more_links_real:</div><div class="line">        more_content = requests.get(more_links_real[<span class="number">0</span>], cookies = get_cookie())</div><div class="line">        more_soup = BeautifulSoup(more_content.content, <span class="string">'html.parser'</span>)</div><div class="line">        more_soup_urls = get_more_page_image_url(more_soup)</div><div class="line">        img_link = more_soup_urls <span class="keyword">if</span> more_soup_urls <span class="keyword">else</span> img_link</div><div class="line"></div><div class="line">    <span class="comment"># download</span></div><div class="line">    <span class="keyword">for</span> idx, link <span class="keyword">in</span> enumerate(img_link):</div><div class="line">        md5 = calculate_md5(link)</div><div class="line">        <span class="keyword">if</span> md5 <span class="keyword">not</span> <span class="keyword">in</span> exists:</div><div class="line">            large_link = replace_part2_in_link(link)</div><div class="line">            image_content = requests.get(large_link, cookies = get_cookie())</div><div class="line"></div><div class="line">            image_name = <span class="string">"&#123;&#125;&gt;&#123;&#125;_&#123;&#125;"</span>.format(wb_post_time, str(idx), md5)</div><div class="line">            <span class="keyword">with</span> open(<span class="string">'./downloads/&#123;&#125;/&#123;&#125;.jpg'</span>.format(user_id, image_name), <span class="string">'wb'</span>) <span class="keyword">as</span> jpg:</div><div class="line">                jpg.write(image_content.content)</div><div class="line"></div><div class="line">                exists.add(image_name)</div><div class="line">                print(<span class="string">'download'</span>, large_link, image_name, datetime.datetime.now())</div><div class="line">                time.sleep(random.random())</div><div class="line">        <span class="keyword">else</span>:</div><div class="line">            print(<span class="string">'jump over:'</span>, link)</div><div class="line"></div><div class="line">sleep = <span class="number">8</span> * random.random()</div><div class="line">print(<span class="string">'sleep'</span>, sleep, <span class="string">'seconds'</span>)</div><div class="line">time.sleep(sleep)</div><div class="line"><span class="keyword">return</span> <span class="keyword">True</span></div></pre></td></tr></table></figure>
<p>在某次打算爬取大量某个博主的图片时，出现了请求失败，查了资料发现是网站有反爬虫功能，于是使用了一些简单的策略，比如请求加上头消息：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">header = &#123;</div><div class="line">      <span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/49.0.2623.112 Safari/537.36'</span>,</div><div class="line">      <span class="string">'Accept'</span>: <span class="string">'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8'</span>,</div><div class="line">      <span class="string">'Accept-Language'</span>: <span class="string">'zh-CN,zh;q=0.8,en;q=0.6'</span></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>除此之外，对请求的cookie也在末尾添加随机数，每次用不同的cookie去请求，并且，每爬取完一个页面的内容，随机休眠0-8秒，这样做虽然抓取速度慢了点，但至少能保证每次抓取不会半途报错。</p>
<p>完整的代码示例<a href="https://github.com/hsqs/spiders/blob/master/weibo/weibo_miner.py" target="_blank" rel="external">点这里</a>。    </p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2015-12-27T05:36:04.000Z"><a href="/2015/12/27/some-usage-of-mybatis-md/">2015-12-27</a></time>
      
      
  
    <h1 class="title"><a href="/2015/12/27/some-usage-of-mybatis-md/">Mybatis 语法上的一些技巧</a></h1>
  

    </header>
    <div class="entry">
      
        <p>Mybatis前后在项目里一共用了大概1年时间，当时为了赶进度，只学了些基本的用法，后来慢慢积累了一些小技巧，其实这些都在官方文档里都有说明，只是自己用到而已。</p>
<h3 id="1、foreach-in灵活使用"><a href="#1、foreach-in灵活使用" class="headerlink" title="1、foreach-in灵活使用"></a>1、foreach-in灵活使用</h3><p>在使用 foreach 标签时，通常用于构建 IN 子查询或插入数据语句，构建 IN 语句的语法如下：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">foreach</span> <span class="attr">collection</span>=<span class="string">"list"</span> <span class="attr">item</span>=<span class="string">"m"</span> <span class="attr">open</span>=<span class="string">"("</span> <span class="attr">separator</span>=<span class="string">","</span> <span class="attr">close</span>=<span class="string">")"</span>&gt;</span></div><div class="line">    #&#123;m&#125;</div><div class="line"><span class="tag">&lt;/<span class="name">foreach</span>&gt;</span></div></pre></td></tr></table></figure>
<p>foreach 的各项参数就不用多解释了，这里，open 和 close 都显示的写到了foreach标签里。同理，当构建插入多条数据的语句时，同样的语法，不过稍有点变化：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">foreach</span> <span class="attr">collection</span>=<span class="string">"list"</span> <span class="attr">item</span>=<span class="string">"m"</span> <span class="attr">separator</span>=<span class="string">","</span>&gt;</span></div><div class="line">    (#&#123;m.id&#125;, #&#123;m.name&#125;)</div><div class="line"><span class="tag">&lt;/<span class="name">foreach</span>&gt;</span></div></pre></td></tr></table></figure>
<p>注意，foreach 里的语句是带了圆括号，去掉了 open 和 close 属性，分隔符依旧是,，这是其中一种对 values 后面 SQL 的一种分解方式，或者用下面这种：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">foreach</span> <span class="attr">collection</span>=<span class="string">"list"</span> <span class="attr">item</span>=<span class="string">"m"</span> <span class="attr">open</span>=<span class="string">"("</span> <span class="attr">separator</span>=<span class="string">"),("</span> <span class="attr">close</span>=<span class="string">")"</span>&gt;</span></div><div class="line">    #&#123;m.id&#125;, #&#123;m.name&#125;</div><div class="line"><span class="tag">&lt;/<span class="name">foreach</span>&gt;</span></div></pre></td></tr></table></figure>
<p>这里唯一注意的是 separator 的变化，这两种插入数据时的写法，效果都是一致的。想到这里，separator 可以是多个字符，甚至是SQL语句的一部分，怎么使用就看业务场景了。</p>
<h3 id="2、SQL-注解"><a href="#2、SQL-注解" class="headerlink" title="2、SQL 注解"></a>2、SQL 注解</h3><p>对于比较简单的一两行的 SQL，可以不用在 mapper 文件里写配置，直接在Java代码里添加注解的方式来实现。这样做还有一个就是在调试的时候，可以不用再去找 xml 文件里的 SQL 代码。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="meta">@Select</span>(<span class="string">"SELECT name FROM user WHERE province_id = #&#123;address&#125; AND gender = #&#123;gender&#125;"</span>)</div><div class="line"><span class="function"><span class="keyword">public</span> List&lt;String&gt; <span class="title">selectName</span><span class="params">(@Param(<span class="string">"address"</span>)</span>Integer address, @<span class="title">Param</span><span class="params">(<span class="string">"gender"</span>)</span><span class="keyword">char</span> gender)</span>;</div></pre></td></tr></table></figure>
<p>除了@Select 注解，还有@Insert、@Update、@Delete，使用方法同上。这样SQL和Java代码放在一起，<br>查看起来非常的方便。</p>
<h3 id="3、注解参数"><a href="#3、注解参数" class="headerlink" title="3、注解参数"></a>3、注解参数</h3><p>在传入多个参数到 Mybatis 的时候，可以用List、Map传递，对于Map这种情况比较麻烦，首先要专门构造一个Map，另外最难以忍受的是用Map传多个参数不知道里面到底有什么内容，只有到执行SQL时才会报出问题，维护起来也极为麻烦。<br>这里可以使用参数注解，省去这一堆步骤。同时，直观的展示有哪些变量传入SQL，这样调用接口传参数就可以了，调用者不用关心 SQL 里参数用的是哪个名字。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> List&lt;String&gt; <span class="title">selectName</span><span class="params">(@Param(<span class="string">"address"</span>)</span>List&lt;Integer&gt; addrs, @<span class="title">Param</span><span class="params">(<span class="string">"gender"</span>)</span><span class="keyword">char</span> gds)</span>;</div></pre></td></tr></table></figure>
<p>在mapper文件里，用 @Param 里的注解名称来取参数，例如这里的address和gender，SQL里取参数方式不变，用#{gender}或${gender}。</p>
<h3 id="4、insert和select语句调优（2016-07-21-补充）"><a href="#4、insert和select语句调优（2016-07-21-补充）" class="headerlink" title="4、insert和select语句调优（2016-07-21 补充）"></a>4、insert和select语句调优（2016-07-21 补充）</h3><p>在插入或查询时，在mapper文件里，select要写resultMap标签来映射属性和列的关系，insert语句要写一个foreach语句来拼接values后面的内容，这一切都没有问题，但是当一次性查询或插入上千、上万条数据，Mybatis就显得力不从心。Mybatis虽然有强大的动态拼接SQL的能力，但此时应用比较简单，可以考虑尽量减少Mybatis的工作，把它仅仅当做是SQL语句来执行。     </p>
<p>对insert语句，values后面的内容可以预先在Java代码里拼接好，直接传入：<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">insert</span> <span class="attr">id</span>=<span class="string">"insertPOJO"</span> <span class="attr">parameterType</span>=<span class="string">"java.util.List"</span>&gt;</span></div><div class="line">    insert into </div><div class="line">        table(...)</div><div class="line">    values</div><div class="line">        <span class="tag">&lt;<span class="name">foreach</span> <span class="attr">collection</span>=<span class="string">"list"</span> <span class="attr">item</span>=<span class="string">"value"</span> <span class="attr">open</span>=<span class="string">"("</span> <span class="attr">separator</span>=<span class="string">","</span> <span class="attr">close</span>=<span class="string">")"</span>&gt;</span></div><div class="line">            $&#123;value&#125;</div><div class="line">        <span class="tag">&lt;/<span class="name">foreach</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">insert</span>&gt;</span></div></pre></td></tr></table></figure></p>
<p>甚至，连foreach标签也去掉，在Java里就全部拼接好。不过我比较倾向于上面这种，可以看出是插入多条数据，又不至于插入速率太慢。  </p>
<p>对select语句类似：<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">select</span> <span class="attr">id</span>=<span class="string">"selectPOJO"</span> <span class="attr">resultType</span>=<span class="string">"java.util.Map"</span>&gt;</span></div><div class="line">    select </div><div class="line">        *</div><div class="line">    from</div><div class="line">        table</div><div class="line">    where</div><div class="line">        ...    </div><div class="line"><span class="tag">&lt;/<span class="name">select</span>&gt;</span></div></pre></td></tr></table></figure></p>
<p>这里让返回值为Map，在Java里用 List&lt;Map&lt;Object, Object&gt;&gt; 接收，剩下的工作就是将返回结果再转换为List&lt;Pojo&gt;对象。工作量增加了一些，但对数据流较大的查询，性能提升比较明显，查一万条（每条接近40列）从接近两秒减少到不到一秒，还是值得的。</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>





<nav id="pagination">
  
    <a href="/" class="alignleft prev">Vorherige Seite</a>
  
  
  <div class="clearfix"></div>
</nav></div></div>
    <div class="clearfix"></div>
  </div>
  <footer id="footer" class="inner"><div class="alignleft">
  
  &copy; 2018 Ling0fa 的博客
  
  <p>Theme by <a href="https://caisiduo.xyz" target="_blank">LightOne</a></p>
</div>
<div class="clearfix"></div></footer>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>
<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>




<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
  $('.fancybox').fancybox();
})(jQuery);
</script>

</body>
</html>
